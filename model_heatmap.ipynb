import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torchvision.models as models
from torch.utils.data import Dataset, DataLoader, random_split
import torchvision.transforms as transforms
from PIL import Image
import cv2
from pathlib import Path
import matplotlib.pyplot as plt

# Model Architecture
class ClosedPose(nn.Module):
    def __init__(self, num_joints=13):
        super(ClosedPose, self).__init__()
        self.name = "pose"
        resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)
        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-2])
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(2048, 512, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Dropout2d(p=0.1),
            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Dropout2d(p=0.1),
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Dropout2d(p=0.1),
            nn.ConvTranspose2d(128, num_joints, kernel_size=4, stride=2, padding=1),
            nn.Conv2d(num_joints, num_joints, kernel_size=1),
        )
    
    def forward(self, x):
        features = self.feature_extractor(x)
        heatmaps = self.decoder(features)
        heatmaps = torch.sigmoid(heatmaps)
        return heatmaps

# Soft Argmax with Threshold
def soft_argmax(heatmaps, threshold=0.1):
    batch_size, num_joints, H, W = heatmaps.shape
    heatmaps = heatmaps.view(batch_size, num_joints, -1)
    heatmaps = F.softmax(heatmaps, dim=-1)
    heatmaps = torch.where(heatmaps > threshold, heatmaps, torch.zeros_like(heatmaps))
    heatmaps = heatmaps / (heatmaps.sum(dim=-1, keepdim=True) + 1e-6)
    x_grid = torch.linspace(0, W - 1, W, device=heatmaps.device).repeat(H, 1).view(H * W)
    y_grid = torch.linspace(0, H - 1, H, device=heatmaps.device).repeat(W, 1).t().contiguous().view(H * W)
    x = torch.sum(heatmaps * x_grid, dim=-1)
    y = torch.sum(heatmaps * y_grid, dim=-1)
    coords = torch.stack((x, y), dim=-1)
    return coords

# Dataset Class
class KeypointDataset(Dataset):
    def __init__(self, images_dir, labels_dir, augment=True, max_images=None):
        self.images_dir = Path(images_dir)
        self.labels_dir = Path(labels_dir)
        self.image_paths = [p for p in self.images_dir.glob("*.jpg") if (self.labels_dir / f"{p.stem}.txt").exists()]
        if max_images is not None:
            self.image_paths = self.image_paths[:max_images]
        self.augment = augment

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        # Load image
        image_path = self.image_paths[idx]
        img = cv2.imread(str(image_path))
        if img is None:
            raise RuntimeError(f"Failed to load image: {image_path}")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = Image.fromarray(img)

        # Load keypoints and visibility
        label_path = self.labels_dir / (image_path.stem + ".txt")
        with open(label_path, 'r') as f:
            line = f.readline().strip()
        parts = line.split()
        kp_values = parts[1:]  # Skip the first value (class label)
        kp_array = np.array(kp_values, dtype=float).reshape(-1, 3)  # Shape: (13, 3)
        keypoints = kp_array[:, 0:2]  # Shape: (13, 2)
        visibility = kp_array[:, 2]   # Shape: (13,)
        
        # Scale keypoints from [0, 1] to [0, 224]
        keypoints *= 224
        keypoints = torch.tensor(keypoints, dtype=torch.float32)
        visibility = torch.tensor(visibility, dtype=torch.float32)

        # Always resize the image to 224x224
        img = TF.resize(img, (224, 224))

        # Apply augmentations if enabled
        if self.augment:
            # RandomHorizontalFlip
            if torch.rand(1) < 0.5:
                img = TF.hflip(img)
                keypoints[:, 0] = 224 - keypoints[:, 0]
                swap_indices = [(1, 2), (3, 4), (5, 6), (7, 8), (9, 10), (11, 12)]
                for left, right in swap_indices:
                    keypoints[[left, right]] = keypoints[[right, left]]
                    visibility[[left, right]] = visibility[[right, left]]
            # RandomRotation
            angle = torch.FloatTensor(1).uniform_(-15, 15).item()
            img = TF.rotate(img, angle)
            cx, cy = 112, 112
            angle_rad = math.radians(angle)
            cos_a = math.cos(angle_rad)
            sin_a = math.sin(angle_rad)
            x = keypoints[:, 0] - cx
            y = keypoints[:, 1] - cy
            keypoints[:, 0] = cx + x * cos_a - y * sin_a
            keypoints[:, 1] = cy + x * sin_a + y * cos_a
            # RandomAffine (scaling only)
            scale = torch.FloatTensor(1).uniform_(0.8, 1.2).item()
            img = TF.affine(img, angle=0, translate=(0, 0), scale=scale, shear=0)
            keypoints *= scale
            keypoints = torch.clamp(keypoints, 0, 224)

        # Always convert to tensor and normalize
        img = TF.to_tensor(img)
        img = TF.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

        return img, keypoints, visibility

# Utility Functions
def generate_heatmap(h, w, keypoints, sigma=4):
    """
    Generate a Gaussian heatmap for each keypoint.
    keypoints: an iterable of (x, y) coordinates (assumed to be in pixel space, e.g. 0-224) 
    visibility: a matching iterable indicating whether each keypoint is visible (non-zero)
    h, w: height and width of the heatmap (typically 224)
    sigma: standard deviation for the Gaussian.
    """
    heatmap = torch.zeros((len(keypoints), h, w))
    # Create coordinate grids with explicit "xy" ordering
    # x_grid and y_grid will both have shape (h, w); x_grid holds the x-coordinate values and y_grid holds y-coordinate values.
    x_grid, y_grid = torch.meshgrid(torch.arange(w), torch.arange(h), indexing="xy")
    for i, ((x, y)) in enumerate(keypoints):
        if x < 0 or x >= w or y < 0 or y >= h:
            continue  # skip invisible keypoints
        # Convert coordinates to int to serve as the center, you can also keep them as float if needed
        x_center, y_center = int(x), int(y)
        # Skip if keypoint lies outside valid bounds
        if x_center < 0 or x_center >= w or y_center < 0 or y_center >= h:
            continue
        if (x,y) == (0,0):
            continue  # skip invisible keypoints
        # Compute the Gaussian heatmap centered at (x_center, y_center)
        heatmap[i] = torch.exp(-((x_grid - x_center)**2 + (y_grid - y_center)**2) / (2 * sigma**2))
    return heatmap



# Training and Evaluation Functions
class KeypointDataset(Dataset):
    def __init__(self, images_dir, labels_dir, transform=None, max_images=None):
        self.images_dir = Path(images_dir)
        self.labels_dir = Path(labels_dir)
        self.image_paths = [p for p in self.images_dir.glob("*.jpg") if (self.labels_dir / f"{p.stem}.txt").exists()]
        if max_images is not None:
            self.image_paths = self.image_paths[:max_images]
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_path = self.image_paths[idx]
        img = cv2.imread(str(image_path))
        if img is None:
            raise RuntimeError(f"Failed to load image: {image_path}")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        if self.transform:
            img = Image.fromarray(img)
            image_tensor = self.transform(img)
        
        label_path = self.labels_dir / (image_path.stem + ".txt")
        with open(label_path, 'r') as f:
            line = f.readline().strip()
        parts = line.split()
        kp_values = parts[1:]
        kp_array = np.array(kp_values, dtype=float).reshape(-1, 3)[:, 0:2]
        kp_array *= 224
        label_tensor = torch.tensor(kp_array, dtype=torch.float32)
        return image_tensor, label_tensor

# Focal Loss
def focal_loss(pred, target, alpha=4, beta=2):
    pred = torch.clamp(pred, 1e-6, 1 - 1e-6)
    pos_loss = -alpha * (1 - pred) ** beta * target * torch.log(pred)
    neg_loss = -(1 - target) * torch.log(1 - pred)
    loss = (pos_loss + neg_loss).mean()
    return loss

# Training Function
def train(model, train_loader, val_loader, batch_size=30, learning_rate=0.00001, num_epochs=150, device='cuda'):
    torch.manual_seed(420)
    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)
    
    H, W = 224, 224
    
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            
            heatmap_outputs = model(images)
            heatmap_outputs = F.interpolate(heatmap_outputs, size=(H, W), mode='bilinear', align_corners=False)
            gt_heatmaps = torch.stack([generate_heatmap(H, W, kp) for kp in labels]).to(device)
            
            loss = focal_loss(heatmap_outputs, gt_heatmaps)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        
        avg_train_loss = running_loss / len(train_loader)
        
        model.eval()
        val_running_loss = 0.0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                heatmap_outputs = model(images)
                heatmap_outputs = F.interpolate(heatmap_outputs, size=(H, W), mode='bilinear', align_corners=False)
                gt_heatmaps = torch.stack([generate_heatmap(H, W, kp) for kp in labels]).to(device)
                loss = focal_loss(heatmap_outputs, gt_heatmaps)
                val_running_loss += loss.item()
        avg_val_loss = val_running_loss / len(val_loader)
        scheduler.step(avg_val_loss)
        
        print(f"Epoch [{epoch+1}/{num_epochs}] Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")
        
        if (epoch + 1) % 10 == 0:
            with torch.no_grad():
                images, labels = next(iter(val_loader))
                images = images.to(device)
                pred_heatmaps = model(images)
                pred_heatmaps = F.interpolate(pred_heatmaps, size=(H, W), mode='bilinear', align_corners=False)
                gt_heatmaps = torch.stack([generate_heatmap(H, W, kp) for kp in labels]).to(device)
                plot_heatmaps(images, gt_heatmaps, pred_heatmaps)
    
    return model

# PCK Evaluation
def compute_pck(outputs, labels, threshold=22.4):
    coords = soft_argmax(outputs)
    batch_size = coords.shape[0]
    labels = labels.view(batch_size, 13, 2)
    distances = torch.norm(coords - labels, dim=2)
    correct = (distances < threshold).float()
    pck_per_sample = correct.mean(dim=1)
    return pck_per_sample.mean().item()

def evaluate(model, data_loader, device='cuda', threshold=22.4):
    model.eval()
    total_loss = 0.0
    total_pck = 0.0
    count = 0
    with torch.no_grad():
        for inputs, labels in data_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            outputs = F.interpolate(outputs, size=(224, 224), mode='bilinear', align_corners=False)
            gt_heatmaps = torch.stack([generate_heatmap(224, 224, kp) for kp in labels]).to(device)
            loss = focal_loss(outputs, gt_heatmaps)
            total_loss += loss.item() * inputs.size(0)
            batch_pck = compute_pck(outputs, labels, threshold)
            total_pck += batch_pck * inputs.size(0)
            count += inputs.size(0)
    avg_loss = total_loss / count
    avg_pck = total_pck / count
    print(f'Validation Loss: {avg_loss:.4f}, PCK: {avg_pck*100:.2f}%')
    return avg_loss, avg_pck

# Visualization
def plot_heatmaps(images, gt_heatmaps, pred_heatmaps, num_samples=2):
    for i in range(min(num_samples, images.size(0))):
        plt.figure(figsize=(15, 5))
        plt.subplot(1, 3, 1)
        img = images[i].cpu().permute(1, 2, 0).numpy()
        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])
        img = np.clip(img, 0, 1)
        plt.imshow(img)
        plt.title("Input Image")
        plt.subplot(1, 3, 2)
        plt.imshow(gt_heatmaps[i, 0].cpu().numpy())
        plt.title("Ground Truth Heatmap")
        plt.subplot(1, 3, 3)
        plt.imshow(pred_heatmaps[i, 0].cpu().numpy())
        plt.title("Predicted Heatmap")
        plt.show()
